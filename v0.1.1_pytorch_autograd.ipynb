{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0c5d3b8",
   "metadata": {},
   "source": [
    "# A gentle introduction to autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54f35984",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa8a1079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /home/jacky/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44.7M/44.7M [00:02<00:00, 16.8MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3a9c71",
   "metadata": {},
   "source": [
    "random datapoint and random label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e63088f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 64, 64])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = torch.rand(1, 3, 64, 64)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63d5dacc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = torch.rand(1, 1000)\n",
    "len(labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78f8ddee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5471, -0.3601, -0.5766, -1.6097, -0.8004, -0.0734, -0.4240,  0.5162,\n",
       "          0.5866, -0.7817, -0.7790, -0.5281, -0.1267, -0.5577, -0.6884, -0.4300,\n",
       "         -0.7605, -0.1028, -0.3426, -0.0780, -1.2749, -0.8207, -1.3612,  0.2971,\n",
       "         -1.0207, -1.2224, -0.8409, -1.0722, -0.9225, -0.3185, -0.7497, -0.4956,\n",
       "         -0.2488, -0.4675, -0.1717, -0.3460,  0.8394, -0.4641, -0.0452,  0.0781,\n",
       "         -0.3977, -0.6807, -1.0175, -0.3272, -0.5962, -0.3508, -0.5133, -0.3403,\n",
       "         -0.9671, -0.8803, -0.5656,  0.5173, -0.2384, -0.5200, -0.2775, -0.9980,\n",
       "         -0.3741, -1.3372, -0.5660, -0.2946,  0.7124,  0.3102,  0.0271,  0.1963,\n",
       "         -0.9435, -0.3425, -0.4200, -0.5194, -0.8051, -1.0086, -1.5574,  0.2412,\n",
       "         -1.3263, -0.2419, -1.1495, -1.1833,  0.0692, -0.4113,  0.3540, -0.1846,\n",
       "         -0.7113, -1.5173, -0.0337, -0.8982, -0.3972,  0.0255, -0.0175,  0.3435,\n",
       "         -0.1315, -0.5954, -1.2194, -0.7814, -1.9044, -0.4405,  0.5860, -1.9948,\n",
       "         -0.6230, -0.2824, -1.5945, -0.1331, -1.0864, -0.9415, -0.9066, -0.1487,\n",
       "          0.1262, -0.6094, -0.3582, -1.3444, -1.0731, -1.6377, -1.1216, -0.8507,\n",
       "          1.1718,  0.4866,  0.3332, -0.9912, -0.6367, -0.5193,  0.5150, -0.4451,\n",
       "         -0.8555,  0.0834,  0.2769, -0.0911,  0.7986, -0.1639,  0.4970, -1.4817,\n",
       "         -1.2631, -1.0635, -1.4782, -1.5670, -1.1171, -1.4924, -0.7305, -1.5775,\n",
       "         -1.0415, -1.1958, -1.4666, -1.6453, -1.6087, -1.7644, -2.2489, -1.5995,\n",
       "         -0.6163, -0.3372, -1.0834, -1.5699, -1.0285, -1.1301,  0.7531,  1.6256,\n",
       "         -0.9923, -0.4615,  0.1430,  0.0855, -0.3703, -0.3184, -0.1032,  0.2691,\n",
       "          0.7039,  1.0604,  0.2778,  0.6373,  0.4820, -0.0028, -0.0951, -0.3559,\n",
       "          0.8179, -0.1985, -0.1376,  1.0484,  0.4621,  0.3161,  0.1390, -0.6354,\n",
       "          0.3548,  0.0981,  0.8277,  0.6500,  0.5338, -0.0221,  0.4805,  0.0796,\n",
       "          0.5647,  0.5633,  0.4425, -0.0908, -0.0525,  0.4555, -0.5118,  0.2559,\n",
       "          0.3447,  0.4533, -0.5023,  0.6587,  0.1011,  0.0947,  0.2068,  0.6377,\n",
       "          0.2087,  0.0686,  0.6373,  0.3384,  0.0476,  0.3148,  0.1308,  0.6682,\n",
       "          1.5344,  0.3925, -0.0498,  0.3631,  0.4377,  0.0213, -0.0164,  0.2006,\n",
       "         -0.0147,  0.4638, -0.1380,  0.8265,  0.2212, -0.0383,  0.0970,  0.7483,\n",
       "          0.2643,  0.5196,  0.2553,  0.8230, -0.4010, -0.1815, -0.0825,  0.5518,\n",
       "          0.4725,  0.0236,  0.6959,  0.8507,  0.5179,  0.3902,  0.8153, -0.0484,\n",
       "          0.6339,  0.0934,  0.2957,  0.1578, -0.0898,  0.1769,  0.4973,  0.0109,\n",
       "          0.6018,  0.2423,  0.3803,  0.7679, -0.9701,  0.6961,  0.8796, -0.3744,\n",
       "          0.4522,  0.3355,  0.0575,  0.2080, -0.2780, -0.5607, -0.4446,  0.5083,\n",
       "          0.8903,  0.8769,  0.2171,  0.5223, -0.1861, -0.4656, -1.0148, -1.0949,\n",
       "         -0.7129,  0.4874, -1.1248, -1.0497, -1.2051, -0.7292, -1.2193, -0.5673,\n",
       "         -0.3481,  0.7416,  0.7051, -0.1645,  0.2622,  0.6431, -0.2157, -0.2270,\n",
       "         -0.9486, -1.6009, -1.0299, -1.5730, -0.5162, -1.1485, -0.9334, -0.6519,\n",
       "         -0.7147, -1.1546, -0.4977, -0.1837, -1.6635, -0.7038, -0.3708, -0.0601,\n",
       "         -0.9741, -0.7848,  0.4095, -0.5281, -1.1847, -0.4234,  0.5467, -0.2541,\n",
       "         -0.3482,  0.2908,  0.5951, -0.3619, -0.6584, -0.7426, -1.2742, -0.8983,\n",
       "         -1.5323, -1.1573, -1.2424, -1.6461, -1.3048, -1.5598, -1.0619, -0.0052,\n",
       "         -0.1670, -0.4617,  0.1891, -0.0947,  0.1575,  0.5059, -0.4356, -0.9988,\n",
       "         -1.3342,  0.1658,  0.6282, -0.9870, -0.4165,  0.6146, -0.6226, -1.4191,\n",
       "         -0.5857,  0.9177, -0.4152, -1.6079, -0.1018, -1.3367, -1.0037, -2.2069,\n",
       "         -1.2373, -0.7369, -0.6532,  0.6535,  1.1363,  0.1018,  0.6330,  0.4413,\n",
       "          0.0514,  0.5368,  0.1049,  0.3502, -0.4151, -0.4807, -1.0735, -0.3502,\n",
       "         -0.8365, -0.5791, -0.6662, -0.3352, -0.6827, -0.2142,  0.0497, -0.8973,\n",
       "         -1.2905,  0.2206, -0.3424, -0.4373,  0.1495, -0.3476, -0.3698, -0.6591,\n",
       "         -0.7830, -0.3457, -0.9310, -1.0277, -0.9989, -0.2695,  0.5532,  0.2185,\n",
       "         -1.2919, -1.6935,  0.1493,  0.3496, -1.1617, -0.6933,  0.1441,  0.3502,\n",
       "         -0.7119,  0.8679,  0.0791, -2.0910, -1.7683, -0.6701, -0.1719, -0.1926,\n",
       "         -0.2453,  0.7694, -0.1290,  0.1213,  2.2145,  0.6970,  0.7414,  0.6205,\n",
       "         -0.3192,  0.4267,  0.2646,  0.8545,  0.5048,  1.2810, -0.2926,  0.1747,\n",
       "          0.1420, -0.7268, -0.3250,  1.4667,  1.8555,  0.3976, -0.7331, -0.0494,\n",
       "          0.2423,  0.5302,  0.3191,  1.3306, -0.2801, -0.3126,  0.3519,  0.2956,\n",
       "          0.7922,  0.2845, -0.0100, -0.6400, -0.1741,  0.1459,  0.3739,  1.6544,\n",
       "          1.1056, -0.3834,  0.0068,  0.1986,  0.7274, -0.4778, -0.5013,  0.3939,\n",
       "          1.3360,  1.2805, -0.0425,  0.7139, -0.7484,  0.5806,  1.2180,  2.6726,\n",
       "          0.8516, -0.2523, -1.1177, -0.3035, -0.1303,  1.4531,  0.7082,  0.6433,\n",
       "          0.6291,  1.0797, -0.3086, -0.0534, -0.1718,  0.4333,  0.5737,  0.2630,\n",
       "         -0.2236,  0.3887,  0.3017, -0.9982, -0.9814, -0.2969, -0.0582,  1.1582,\n",
       "          1.4734,  1.2841,  0.4993,  0.8158,  0.6352, -1.3326,  1.1042, -1.2580,\n",
       "         -0.1121, -0.4996, -0.7499,  1.1499, -1.6262,  0.8121,  1.1899,  0.6309,\n",
       "          0.9679,  1.3908,  0.8219,  0.5729,  0.2844,  0.2046, -1.3266, -0.8533,\n",
       "          1.0101,  0.3058,  1.1451,  1.4708,  0.4201, -0.3230,  1.3203,  0.7364,\n",
       "         -0.6642,  0.4652,  0.8455,  1.6946,  0.4759, -0.4270, -0.2859, -0.6655,\n",
       "          0.1578,  0.0618,  0.8332,  0.0784, -0.0639, -1.0031,  0.6312, -0.7324,\n",
       "         -0.4064, -0.6011,  0.1512,  1.0566, -1.4223,  1.5903,  1.0004,  0.7779,\n",
       "          0.8442,  0.8838,  0.5364, -1.9052, -1.5725,  0.0113, -0.3361,  0.1018,\n",
       "          0.8286, -0.3850, -1.2558, -0.6242,  0.5170,  0.3902,  1.2607,  0.8743,\n",
       "          0.2162, -0.2581,  0.8484,  0.0240, -1.3104, -0.5701,  0.0055,  1.1608,\n",
       "          0.3940, -0.6148,  1.1455,  0.1925,  0.6336, -0.8114,  0.4611, -0.1199,\n",
       "         -0.6416,  0.9659,  0.3577,  0.0547,  0.4115, -0.0309,  0.5409,  0.9240,\n",
       "          1.1324,  0.9437, -0.1646,  1.8637,  1.3354,  0.9979, -0.5573,  0.2578,\n",
       "         -0.6602,  0.9336,  0.4324, -0.6902,  1.0949, -0.3518, -0.8570,  0.7757,\n",
       "          2.0737, -0.1522, -0.0685, -0.5444,  0.4745,  0.3516,  1.0866, -0.5697,\n",
       "          0.3297, -0.0519,  1.0294,  0.5173, -0.7105,  0.4561,  0.0622,  0.2745,\n",
       "          0.8372,  0.3405,  1.7992,  0.7250,  1.2113,  0.8388,  0.3529,  0.6242,\n",
       "         -0.0459, -1.1758,  1.1986, -0.4001, -1.2742,  0.2471,  0.0628,  1.0934,\n",
       "          0.6257,  1.2703, -0.1833, -0.0736,  1.3906,  0.9047,  0.8257,  0.3706,\n",
       "         -1.6164,  1.0750, -0.0925,  1.4899,  0.7663, -0.9779,  0.5046,  0.3067,\n",
       "         -0.7846, -1.5294,  0.8125,  0.1761,  0.4529,  0.7123, -0.2936,  0.5601,\n",
       "         -0.3268, -0.0148,  0.0288,  0.4741,  0.0669, -1.1036, -0.1235, -0.8238,\n",
       "          0.8018,  0.0313,  1.1740,  0.3769, -0.7731, -0.2423,  0.2301, -0.2206,\n",
       "          0.0732,  0.4576,  1.5856, -0.6209,  1.7496,  1.0312,  0.9471,  0.1175,\n",
       "          0.5743,  0.7174, -0.5721,  0.5220,  0.8075, -1.5789, -0.0427, -1.1106,\n",
       "         -0.2889, -0.5889, -0.4596,  0.7192,  0.7958,  0.8045, -0.8921,  0.8563,\n",
       "          1.4399, -0.3187, -0.4955,  0.6582,  1.5661, -0.1248, -0.1038,  0.5991,\n",
       "          0.4944, -0.3636, -0.5242,  0.3932,  0.8346,  0.1669,  1.0992,  1.1789,\n",
       "         -0.0322, -0.3702,  0.1187, -0.3973,  0.6947, -0.6841, -0.5282,  0.6483,\n",
       "          0.2557,  0.2917,  1.3901,  0.4707, -0.5375,  1.1142, -0.4926, -0.1509,\n",
       "          1.5738, -0.5446,  0.2021,  2.0603, -0.3833,  1.9697, -1.4724,  0.1985,\n",
       "         -0.1938,  0.5839,  1.0747,  0.1091,  0.9603, -0.1969,  0.3082,  0.5666,\n",
       "          0.6576,  0.0871,  0.2262,  0.7684,  0.9809,  1.5576,  0.2206, -0.1997,\n",
       "          0.4489,  0.6857,  0.6669, -0.7353,  1.1826, -0.1904,  1.4720,  0.1350,\n",
       "         -0.0121,  0.6122,  0.2613,  0.9867,  1.3039,  0.8321,  0.2746,  0.0397,\n",
       "         -0.0244,  1.2470,  0.6100,  0.3809,  1.3554,  0.7101,  1.0990,  0.3285,\n",
       "          0.3011,  0.8312,  1.3232, -0.6902, -0.9927, -1.0493,  0.8893,  0.6472,\n",
       "          1.6144,  0.1920,  0.6330,  1.6233,  0.1169, -0.1802,  0.5928,  1.0788,\n",
       "          1.6422,  0.8337,  0.1533,  0.1979,  1.0675,  0.7056, -0.5877,  0.5266,\n",
       "         -1.5116,  0.1956, -1.0770, -1.0617,  1.3313,  1.2112,  0.3819,  0.0583,\n",
       "          1.2051, -0.1114, -0.2661,  1.2464, -0.2083,  1.6424, -0.8588, -0.1034,\n",
       "          0.0631, -1.1449,  1.5886,  0.2316, -1.5331, -0.9036,  0.3042,  0.6712,\n",
       "          0.9999, -0.7591,  0.2363,  0.8596,  1.3142, -0.4797,  1.1665,  0.2376,\n",
       "         -0.9219, -1.1572,  0.1590,  0.1659,  1.6594,  1.5071,  1.0657, -0.4909,\n",
       "          1.0543,  0.3592,  0.2954,  0.5861,  0.6147,  1.7245,  0.5388, -0.3263,\n",
       "          0.5251,  0.9535,  1.4858,  1.1821,  1.9347, -0.6858, -0.5743,  0.6782,\n",
       "         -0.7025, -0.2414, -0.1832,  1.3620, -0.1281,  1.3057,  0.8076,  0.0807,\n",
       "         -0.4525,  0.3856,  0.2353, -0.0458,  1.4066, -0.4756,  0.9865, -1.2361,\n",
       "          1.1258, -1.1559, -2.3511,  0.2591,  1.8588, -0.2462, -0.2195,  1.5008,\n",
       "          0.8326, -0.1999,  1.0321,  1.1444, -0.0604, -0.0279, -0.7584, -0.0944,\n",
       "         -1.0620,  0.1398, -0.0695,  0.0385,  0.6442,  0.4118, -0.9346, -0.6456,\n",
       "          0.9404,  0.8583,  1.9634,  1.9181, -1.1980, -0.4322,  1.5904,  0.7738,\n",
       "          1.0195, -0.0558, -0.4055,  1.4116, -0.7992,  0.7877,  1.2708,  0.8148,\n",
       "          0.9576, -0.4423, -1.5992, -0.2577,  0.1195,  0.1446,  0.4429,  0.0127,\n",
       "         -0.4322,  1.2631, -1.0018,  0.3158, -0.3484, -1.2960, -1.3105, -0.6835,\n",
       "         -0.2833,  1.6654, -0.3639, -0.1008,  0.1063, -1.6892,  0.0899, -0.5821,\n",
       "          0.4296,  0.2719,  0.1608,  0.0224, -0.1285, -0.6666, -0.1123,  0.2358,\n",
       "         -0.5401, -0.7053, -1.3633,  0.2663,  0.5967, -0.5406, -0.1489, -0.6461,\n",
       "         -0.7836,  0.0042,  0.6306, -0.5194, -0.4100, -0.5974, -0.1207, -1.3211,\n",
       "          0.0902,  0.2113, -0.6172, -0.9054, -1.6587, -0.2802,  0.4051, -0.7985,\n",
       "          0.6330, -0.2354, -0.1215,  1.4270, -0.3042, -0.3143, -1.9312,  1.0316,\n",
       "         -1.7563,  0.3233,  0.1087, -0.5793, -0.6230, -0.0742,  0.4318, -0.4032,\n",
       "         -0.7828, -1.1143, -2.2111,  1.5048, -0.2372, -1.0638, -0.4033, -1.2093,\n",
       "         -1.1535, -1.9759, -0.7875, -0.5344,  0.2673, -0.5058,  1.4395,  1.0393]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# forward pass\n",
    "prediction = model(data)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25bc409a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-509.2353, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = (prediction - labels).sum()\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e21a0dd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a98653f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e268712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGD (\n",
       "Parameter Group 0\n",
       "    dampening: 0\n",
       "    differentiable: False\n",
       "    foreach: None\n",
       "    fused: None\n",
       "    lr: 0.01\n",
       "    maximize: False\n",
       "    momentum: 0.95\n",
       "    nesterov: False\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optim = torch.optim.SGD(\n",
    "    model.parameters(),\n",
    "    lr=1e-2,\n",
    "    momentum=0.95\n",
    ")\n",
    "optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f25aba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ae32e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c77cb2c6",
   "metadata": {},
   "source": [
    "# differentiation in autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fd62f76a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([3., 4.], requires_grad=True), tensor([5., 7.], requires_grad=True))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.tensor([3., 4.], requires_grad=True)\n",
    "b = torch.tensor([5., 7.], requires_grad=True)\n",
    "a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "06dd54d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 56., 143.], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q = 3*a**3 - b**2\n",
    "Q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1312dc",
   "metadata": {},
   "source": [
    "if we have `a` and `b` be the parameters of the NN, and `Q` to be the error, then we want the gradients of the errors to be the partial derivatives with respect to the parameters. Calling something like `.backward()` on `Q`, the autograd function will automatically calculate the partial derivatives (graidents and store them in the tensor's `.grad` attribute). a specific `gradient` argument is neeeded in `Q.backward()` since it is a vector. We can also aggregate `Q` into a scalar using `.sum()`, then pass the backward argument on top. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c2fa9a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "external_grad = torch.tensor([1., 1.])\n",
    "Q.backward(gradient = external_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1ba8abe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([3., 4.], requires_grad=True),\n",
       " tensor([5., 7.], requires_grad=True),\n",
       " tensor([ 56., 143.], grad_fn=<SubBackward0>))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, b, Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8be09a2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 81., 144.]), tensor([-10., -14.]))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.grad, b.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f9f07f58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 81., 144.], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "9*a**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6e4d4722",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-10., -14.], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-2*b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2628a759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([True, True])\n",
      "tensor([True, True])\n"
     ]
    }
   ],
   "source": [
    "print(9*a**2 == a.grad)\n",
    "print(-2*b == b.grad)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

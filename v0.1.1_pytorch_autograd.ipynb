{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0c5d3b8",
   "metadata": {},
   "source": [
    "# A gentle introduction to autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54f35984",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa8a1079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3a9c71",
   "metadata": {},
   "source": [
    "random datapoint and random label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e63088f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 64, 64])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = torch.rand(1, 3, 64, 64)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "63d5dacc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = torch.rand(1, 1000)\n",
    "len(labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "78f8ddee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-6.3137e-01, -5.1080e-01, -1.9999e-01, -1.4795e+00, -4.7816e-01,\n",
       "         -3.1859e-03, -5.1857e-01,  4.0462e-01,  2.7463e-01, -9.4749e-01,\n",
       "         -1.1470e+00, -9.0036e-01, -5.1541e-01, -8.9454e-01, -1.4960e+00,\n",
       "         -6.8003e-01, -6.6436e-01, -3.3788e-01, -5.0312e-01, -4.7172e-01,\n",
       "         -1.4053e+00, -6.8696e-01, -1.5180e+00,  9.7142e-02, -9.0908e-01,\n",
       "         -1.3029e+00, -1.0694e+00, -1.3421e+00, -1.0289e+00, -6.3022e-01,\n",
       "         -1.2259e+00, -9.3632e-01, -7.3545e-01, -4.2059e-01, -3.0475e-01,\n",
       "         -4.0363e-01,  6.5356e-01, -6.9702e-01, -3.6015e-01, -1.6268e-01,\n",
       "         -9.7075e-01, -1.0906e+00, -1.3824e+00, -5.9527e-01, -7.7175e-01,\n",
       "         -2.5186e-01, -9.2992e-01, -7.5942e-01, -1.2696e+00, -9.1445e-01,\n",
       "         -2.2646e-01,  5.5522e-01, -5.3136e-01, -4.3897e-01, -1.4480e-01,\n",
       "         -1.0336e+00, -1.4188e-01, -1.4580e+00, -2.6605e-01, -4.3717e-01,\n",
       "          7.2876e-01,  1.3341e-01, -2.0620e-01,  2.8914e-01, -7.8507e-01,\n",
       "         -4.6990e-02, -1.1672e-01,  6.5214e-02, -6.6119e-01, -1.0229e+00,\n",
       "         -1.7509e+00, -9.4969e-02, -1.5593e+00, -2.8189e-01, -1.2776e+00,\n",
       "         -1.1705e+00, -7.6565e-02, -6.5542e-01, -3.4712e-02,  1.1305e-01,\n",
       "         -1.0257e+00, -1.4021e+00, -1.7528e-01, -7.6173e-01, -6.9843e-01,\n",
       "         -1.4195e-01, -8.4338e-02,  6.1522e-01, -3.6044e-01, -6.5088e-01,\n",
       "         -1.2277e+00, -1.0828e+00, -1.9645e+00, -3.7839e-01,  5.2023e-02,\n",
       "         -2.2567e+00, -3.9497e-01, -2.4885e-01, -1.3483e+00, -5.9292e-02,\n",
       "         -1.1178e+00, -1.0967e+00, -8.4381e-01, -2.5954e-01, -5.2418e-01,\n",
       "         -7.7005e-01, -6.7128e-01, -9.9615e-01, -6.5955e-01, -1.4802e+00,\n",
       "         -1.0910e+00, -7.1811e-01,  1.0376e+00,  3.5699e-02,  5.2397e-02,\n",
       "         -8.9750e-01, -8.9045e-01, -4.0589e-01,  6.1247e-01, -6.2385e-01,\n",
       "         -1.0641e+00,  7.5072e-02, -1.3137e-01, -1.1549e-01,  6.4229e-01,\n",
       "         -1.6486e-01,  1.2553e-01, -1.4646e+00, -1.3826e+00, -1.2145e+00,\n",
       "         -1.5299e+00, -1.4621e+00, -9.8546e-01, -1.2329e+00, -7.0395e-01,\n",
       "         -1.4910e+00, -1.2274e+00, -1.1208e+00, -1.3376e+00, -1.5203e+00,\n",
       "         -1.8848e+00, -1.7380e+00, -2.4079e+00, -1.5859e+00, -7.9312e-01,\n",
       "         -3.7303e-01, -9.8625e-01, -1.9381e+00, -1.1232e+00, -1.0987e+00,\n",
       "          6.4921e-01,  1.6626e+00, -1.0372e+00, -3.2231e-01, -4.8493e-02,\n",
       "          2.1691e-01, -4.4194e-01, -4.2530e-01,  2.1845e-01,  1.9030e-01,\n",
       "          7.1226e-01,  7.7172e-01,  4.2764e-01,  5.8899e-01,  4.9722e-01,\n",
       "         -1.3438e-02,  5.1680e-03, -3.1805e-01,  7.9806e-01, -3.1905e-01,\n",
       "          1.8737e-02,  1.0166e+00,  6.7732e-01,  4.5775e-01,  5.3944e-02,\n",
       "         -7.0323e-01,  3.4277e-01,  2.6838e-01,  1.1069e+00,  6.5822e-01,\n",
       "          6.4047e-01,  2.6037e-01,  5.7246e-01,  1.7088e-01,  4.0714e-01,\n",
       "          4.6897e-01,  3.9846e-01, -1.1259e-01,  2.6091e-01,  5.7822e-01,\n",
       "         -4.7743e-01,  3.0127e-01,  3.4783e-01,  5.4415e-01, -5.3229e-01,\n",
       "          9.0251e-01,  1.7974e-01,  3.1797e-01,  8.6365e-02,  7.6521e-01,\n",
       "          1.0177e-01,  8.6599e-04,  5.5741e-01,  7.4922e-01,  1.3722e-01,\n",
       "          4.2949e-01,  4.4137e-02,  6.5351e-01,  1.4744e+00,  6.4590e-01,\n",
       "          2.4575e-01,  6.6331e-01,  8.5710e-01,  4.4750e-02,  2.1715e-01,\n",
       "          3.5672e-01, -5.4839e-02,  6.4955e-01, -1.9901e-01,  9.6567e-01,\n",
       "          2.7625e-01,  4.9435e-02, -3.5957e-02,  7.9575e-01, -3.0438e-02,\n",
       "          4.5333e-01,  3.6003e-01,  9.7912e-01, -2.8363e-02,  1.0598e-01,\n",
       "         -2.3679e-01,  3.2722e-01,  5.7174e-01, -9.0200e-02,  8.4856e-01,\n",
       "          7.8248e-01,  6.5767e-01,  6.5552e-01,  9.3709e-01,  9.4239e-02,\n",
       "          6.3805e-01,  1.9518e-01,  5.0982e-01,  1.6132e-02, -4.7430e-01,\n",
       "          4.9091e-01,  5.3810e-01, -1.5151e-01,  6.3820e-01,  2.5009e-01,\n",
       "          5.9376e-01,  7.8702e-01, -9.8627e-01,  6.6506e-01,  7.6733e-01,\n",
       "         -1.0501e+00,  4.4061e-01,  4.3690e-01, -1.0267e-01, -3.5765e-02,\n",
       "         -6.2106e-01, -7.5653e-01, -5.5512e-01,  2.6147e-01,  5.6275e-01,\n",
       "          8.6630e-01,  4.7761e-01,  7.9763e-01,  5.6084e-02, -5.2508e-01,\n",
       "         -8.6873e-01, -1.2363e+00, -7.5879e-01,  4.8714e-01, -1.6899e+00,\n",
       "         -1.3268e+00, -1.1781e+00, -1.3143e+00, -1.7654e+00, -7.1604e-01,\n",
       "         -6.0843e-01,  5.5747e-01,  4.8481e-01, -1.9360e-01,  4.6445e-01,\n",
       "          9.0480e-01,  6.0513e-03, -3.6223e-01, -7.1225e-01, -1.4849e+00,\n",
       "         -9.6817e-01, -1.6411e+00, -6.9481e-01, -1.0061e+00, -1.1140e+00,\n",
       "         -9.8325e-01, -7.5753e-01, -1.5512e+00, -6.4802e-01, -3.1072e-01,\n",
       "         -2.3134e+00, -5.7056e-01, -5.5153e-01, -6.8845e-01, -1.3975e+00,\n",
       "         -1.0011e+00,  1.6245e-01, -6.1060e-01, -1.6349e+00, -1.0229e+00,\n",
       "          6.3338e-01, -8.0875e-01, -7.8171e-01,  2.3323e-01,  2.5456e-01,\n",
       "         -6.4887e-01, -1.0368e+00, -1.4290e+00, -1.0805e+00, -8.8798e-01,\n",
       "         -1.5284e+00, -1.1971e+00, -1.5729e+00, -1.6366e+00, -1.8425e+00,\n",
       "         -1.7579e+00, -1.4979e+00,  1.3498e-01,  1.5049e-01, -1.6382e-01,\n",
       "         -2.4376e-01, -3.3966e-01, -2.5628e-02,  6.5218e-02, -2.4401e-01,\n",
       "         -1.1552e+00, -1.7716e+00,  1.0487e-02,  4.0084e-01, -1.0984e+00,\n",
       "         -5.4886e-01,  2.9872e-01, -9.5235e-01, -1.6508e+00, -8.3215e-01,\n",
       "          3.2647e-01, -8.1907e-01, -1.8450e+00, -1.5793e-01, -1.2390e+00,\n",
       "         -1.0994e+00, -2.1573e+00, -1.5247e+00, -8.3607e-01, -9.0245e-01,\n",
       "          3.3052e-01,  8.0887e-01, -1.6496e-01,  2.3828e-01,  2.3214e-01,\n",
       "         -1.8632e-01,  5.1954e-01,  6.6050e-02,  3.1123e-01, -2.9055e-01,\n",
       "         -5.9449e-01, -1.3257e+00, -4.0901e-01, -1.0793e+00, -6.2757e-01,\n",
       "         -7.7254e-01, -5.0016e-01, -5.9326e-01, -2.1672e-01, -4.1234e-01,\n",
       "         -1.1618e+00, -1.2575e+00,  3.8755e-02, -2.8344e-01, -8.8501e-01,\n",
       "          1.4417e-01, -5.2684e-01, -5.2235e-01, -7.0070e-01, -9.8031e-01,\n",
       "         -4.2733e-01, -8.8618e-01, -1.4704e+00, -1.2763e+00, -3.5058e-01,\n",
       "          4.4024e-01,  2.2755e-01, -1.6746e+00, -1.4110e+00,  3.5384e-02,\n",
       "          5.9157e-01, -1.1095e+00, -5.1917e-01,  3.6757e-01,  3.3525e-01,\n",
       "         -8.3823e-01,  7.8304e-01,  3.5279e-01, -2.4071e+00, -1.9527e+00,\n",
       "         -3.7751e-01, -6.1327e-02, -3.7901e-01, -5.2623e-01,  1.1572e+00,\n",
       "         -3.3834e-01,  4.4733e-01,  2.0954e+00,  6.3711e-01,  4.5070e-01,\n",
       "          8.1377e-01, -3.2022e-01,  6.7363e-01,  2.0402e-01,  1.4031e+00,\n",
       "          1.0366e+00,  1.3280e+00, -9.4167e-02,  5.5678e-01,  2.9202e-01,\n",
       "         -7.3325e-01,  3.2870e-02,  1.2712e+00,  1.6087e+00,  5.9467e-01,\n",
       "         -8.9907e-01,  4.2470e-01,  2.6328e-01,  5.8328e-01,  5.0954e-01,\n",
       "          1.1660e+00, -2.2543e-01, -6.0779e-01,  4.5364e-01, -2.7994e-01,\n",
       "          1.0067e+00,  4.7907e-01,  1.4925e-01, -4.6384e-01, -2.3152e-02,\n",
       "          3.5581e-01,  5.5257e-01,  1.3266e+00,  5.5011e-01, -8.0512e-01,\n",
       "         -5.4147e-01,  3.2972e-01,  6.0747e-01,  2.8719e-01,  1.3048e-01,\n",
       "          2.7746e-01,  1.6020e+00,  1.6892e+00, -2.6271e-02,  9.1483e-01,\n",
       "         -6.9231e-01,  6.1936e-01,  1.5818e+00,  2.4339e+00,  1.0221e+00,\n",
       "         -3.0630e-01, -1.2764e+00, -4.5408e-01,  1.0313e-01,  1.3601e+00,\n",
       "          1.2395e+00,  2.0752e-01,  3.5339e-01,  9.6078e-01, -4.3226e-01,\n",
       "          2.1520e-01,  1.9555e-02,  4.2590e-01,  8.2193e-01,  3.4003e-01,\n",
       "          1.8513e-01,  3.7226e-01,  3.8500e-01, -9.5912e-01, -1.2754e+00,\n",
       "         -1.2357e-01, -3.5857e-01,  1.2107e+00,  1.6570e+00,  1.0437e+00,\n",
       "          5.4445e-01,  8.4762e-01,  8.9498e-01, -1.2016e+00,  1.0150e+00,\n",
       "         -6.2101e-01,  1.4508e-01, -3.2305e-01,  6.0158e-02,  1.2222e+00,\n",
       "         -1.4375e+00,  5.4048e-01,  1.1744e+00,  7.1849e-01,  9.9445e-01,\n",
       "          1.3193e+00,  1.0271e+00,  5.4212e-01,  3.2353e-01,  2.7419e-01,\n",
       "         -1.0578e+00, -8.0099e-01,  7.4869e-01,  1.3618e-01,  1.1039e+00,\n",
       "          1.8300e+00,  6.3176e-01, -2.1839e-01,  1.1707e+00,  1.0887e+00,\n",
       "         -4.1627e-01,  2.4557e-01,  1.2270e+00,  1.6528e+00,  3.4530e-01,\n",
       "         -8.5113e-01,  1.9931e-01, -5.0036e-01,  2.7086e-01,  2.1096e-02,\n",
       "          1.0039e+00,  2.4796e-01,  1.1188e-01, -9.7753e-01,  2.9173e-01,\n",
       "         -7.8914e-01, -5.4545e-01, -7.4037e-01,  3.1068e-01,  1.2557e+00,\n",
       "         -1.3985e+00,  1.4354e+00,  9.8861e-01,  8.4855e-01,  4.2988e-01,\n",
       "          1.1425e+00,  5.1412e-01, -2.1060e+00, -8.1285e-01,  2.1715e-01,\n",
       "         -2.5908e-01,  1.7524e-01,  9.2907e-01,  4.2414e-02, -1.5400e+00,\n",
       "         -7.1793e-01,  4.0883e-01,  2.7043e-01,  1.2477e+00,  6.6191e-01,\n",
       "         -7.1256e-03,  1.4605e-01,  9.7789e-01,  3.3682e-02, -1.0635e+00,\n",
       "         -6.5756e-01, -1.1930e-01,  1.2378e+00,  3.5012e-01, -4.6159e-01,\n",
       "          1.1917e+00, -7.9430e-02,  8.1439e-01, -7.2530e-01,  8.3959e-01,\n",
       "          1.5977e-01, -6.8067e-01,  9.5173e-01,  4.8101e-01,  2.0020e-01,\n",
       "          5.0316e-01, -2.1274e-01,  5.7875e-01,  6.4806e-01,  7.4584e-01,\n",
       "          7.1665e-01, -4.7787e-01,  1.9140e+00,  1.1063e+00,  1.3513e+00,\n",
       "         -3.6945e-01,  5.9222e-01, -7.5507e-01,  7.7357e-01,  2.1956e-01,\n",
       "         -7.0972e-01,  1.0060e+00, -1.2815e-01, -3.5645e-01,  9.0833e-01,\n",
       "          2.1767e+00,  7.6771e-02,  2.0179e-02, -6.3749e-01,  5.2167e-01,\n",
       "          1.9867e-01,  1.3384e+00, -5.2348e-01,  5.4217e-01, -2.4739e-01,\n",
       "          1.1209e+00,  4.3421e-01, -5.7255e-01,  7.6110e-01, -8.2702e-03,\n",
       "          2.7157e-01,  1.2405e+00,  7.5991e-01,  2.2388e+00,  1.0788e+00,\n",
       "          1.1007e+00,  7.7925e-01,  7.1258e-02,  5.9660e-01,  3.0059e-01,\n",
       "         -1.1917e+00,  1.2707e+00, -4.9690e-02, -1.0732e+00,  3.7383e-01,\n",
       "         -7.1333e-02,  9.9205e-01,  9.6776e-01,  9.6626e-01, -1.8545e-01,\n",
       "          4.5288e-01,  1.2803e+00,  3.4466e-01,  7.0200e-01,  2.1181e-01,\n",
       "         -1.5474e+00,  1.3018e+00, -4.4192e-01,  1.4344e+00,  1.0779e+00,\n",
       "         -8.7420e-01,  8.9210e-01,  6.5601e-01, -4.5799e-01, -1.1339e+00,\n",
       "          1.3880e+00,  2.2582e-01,  4.8530e-01,  6.8167e-01, -8.3998e-02,\n",
       "          8.1733e-01,  1.6497e-02, -7.4368e-02,  5.9276e-02,  5.5602e-01,\n",
       "         -1.9800e-01, -1.0699e+00, -1.6398e-02, -8.9469e-01,  1.1064e+00,\n",
       "          2.4086e-02,  1.1698e+00,  1.9243e-01, -5.6086e-01,  4.7199e-02,\n",
       "          1.9788e-01, -9.1608e-02, -1.5524e-01,  7.2668e-01,  1.2513e+00,\n",
       "         -7.5886e-01,  1.5257e+00,  1.1745e+00,  1.3315e+00,  2.4394e-01,\n",
       "          7.6475e-01,  7.1974e-01, -4.5354e-01,  4.0609e-01,  6.9799e-01,\n",
       "         -1.3666e+00, -1.6701e-02, -7.7613e-01, -1.9328e-01, -7.9916e-01,\n",
       "         -6.6302e-01,  1.0320e+00,  9.5809e-01,  8.1711e-01, -9.2534e-01,\n",
       "          6.7238e-01,  1.3721e+00,  6.5224e-02, -2.7642e-01,  8.5368e-01,\n",
       "          1.9339e+00, -1.8785e-02, -1.1144e-01,  5.3504e-01,  5.8888e-01,\n",
       "         -3.3772e-01, -4.7833e-01,  3.8392e-01,  1.0867e+00,  8.0575e-02,\n",
       "          8.8170e-01,  9.7754e-01,  9.9204e-02, -2.4784e-01,  2.6376e-01,\n",
       "         -3.3193e-01,  7.7504e-01, -6.3763e-01, -3.5032e-01,  3.9224e-01,\n",
       "          5.0244e-01,  4.1700e-01,  1.1703e+00,  3.9748e-01, -5.5902e-01,\n",
       "          1.3708e+00, -5.8755e-01,  3.4520e-01,  1.4365e+00, -3.8181e-01,\n",
       "         -6.5628e-02,  2.2083e+00, -4.7613e-01,  2.0291e+00, -1.4462e+00,\n",
       "          1.9746e-01, -4.5045e-02,  5.3118e-01,  9.7612e-01, -3.0696e-02,\n",
       "          9.7705e-01, -3.2106e-01,  3.5026e-01,  5.7200e-01,  5.9555e-01,\n",
       "         -1.8405e-02,  3.9024e-01,  4.7790e-01,  7.0126e-01,  1.4608e+00,\n",
       "          5.8278e-01, -3.9239e-01,  4.8956e-01,  2.7226e-01,  9.0318e-01,\n",
       "         -3.6789e-01,  9.4040e-01, -2.7013e-02,  1.4231e+00, -1.5205e-01,\n",
       "          7.9986e-02,  6.3634e-01,  3.1596e-01,  5.5160e-01,  1.1618e+00,\n",
       "          1.2193e+00,  3.3793e-01,  3.8852e-01, -2.9133e-01,  1.4565e+00,\n",
       "          2.3530e-01,  6.5680e-01,  1.4782e+00,  6.5456e-01,  1.3515e+00,\n",
       "          3.3149e-01,  4.0629e-01,  5.8406e-01,  1.3010e+00, -6.3435e-01,\n",
       "         -7.4992e-01, -6.6440e-01,  1.2753e+00,  8.3407e-01,  1.4973e+00,\n",
       "          5.8972e-01,  4.5190e-01,  1.0963e+00,  2.2274e-01, -7.9538e-03,\n",
       "          6.1941e-01,  1.1118e+00,  1.8007e+00,  1.3457e+00,  6.9054e-01,\n",
       "          5.4315e-01,  1.0311e+00,  9.6253e-01, -3.2988e-01,  5.0343e-01,\n",
       "         -8.0119e-01,  4.7588e-01, -1.2018e+00, -1.1672e+00,  1.1261e+00,\n",
       "          1.0831e+00,  2.7095e-01,  4.0492e-01,  1.2389e+00, -5.8243e-02,\n",
       "         -5.1743e-01,  1.1763e+00, -2.6591e-01,  1.6026e+00, -1.0892e+00,\n",
       "         -2.2931e-01,  2.2245e-01, -1.2675e+00,  1.9414e+00,  6.8256e-01,\n",
       "         -1.6401e+00, -8.9495e-01,  3.3818e-01,  1.1090e+00,  1.0440e+00,\n",
       "         -6.6437e-01,  1.4555e-01,  9.9776e-01,  1.3212e+00, -4.7675e-01,\n",
       "          1.0436e+00,  5.4686e-01, -6.6732e-01, -1.0996e+00,  5.2208e-01,\n",
       "          4.5823e-01,  1.7728e+00,  1.8345e+00,  1.0987e+00, -5.8282e-01,\n",
       "          1.4825e+00,  1.8979e-01,  4.6589e-01,  7.2653e-01,  3.4717e-01,\n",
       "          1.7300e+00,  8.1819e-01, -8.8123e-01,  3.7452e-01,  1.0931e+00,\n",
       "          1.1738e+00,  1.5248e+00,  2.0030e+00, -3.2845e-01, -2.2544e-01,\n",
       "          7.1067e-01, -8.1275e-01, -4.3114e-02, -4.5405e-01,  1.0259e+00,\n",
       "          1.4984e-01,  1.5630e+00,  7.4792e-01,  1.8471e-01, -6.8617e-01,\n",
       "          4.7505e-01, -1.2491e-01, -3.2692e-01,  1.6824e+00, -2.5737e-01,\n",
       "          1.1019e+00, -1.5267e+00,  1.2995e+00, -6.9879e-01, -2.1243e+00,\n",
       "          1.3901e-01,  1.7197e+00, -7.4403e-04, -2.0272e-01,  1.7071e+00,\n",
       "          1.4765e+00, -5.8534e-01,  1.0054e+00,  1.2432e+00,  3.0999e-01,\n",
       "          2.8662e-01, -2.6183e-01, -2.7043e-01, -9.4290e-01,  7.0523e-02,\n",
       "         -2.4806e-01,  4.1597e-01,  7.2137e-01,  2.1302e-01, -4.0644e-01,\n",
       "         -5.8704e-01,  1.3370e+00,  7.2576e-01,  1.9837e+00,  2.0745e+00,\n",
       "         -1.0268e+00, -6.0259e-01,  1.5889e+00,  8.9859e-01,  9.3170e-01,\n",
       "          2.3779e-01, -2.3142e-01,  1.3978e+00, -1.0400e+00,  1.1536e+00,\n",
       "          1.3777e+00,  1.0029e+00,  8.6405e-01, -2.8976e-01, -1.9218e+00,\n",
       "         -9.7300e-02,  3.3129e-01,  5.3261e-01,  3.6355e-01,  1.1098e-01,\n",
       "         -1.2583e-01,  1.4731e+00, -4.1192e-01,  3.6173e-01, -4.0256e-01,\n",
       "         -1.1203e+00, -1.2140e+00, -5.9328e-01,  8.1251e-02,  1.6307e+00,\n",
       "         -4.3156e-01,  2.5527e-02,  3.2880e-01, -1.7532e+00, -1.7082e-01,\n",
       "         -5.8869e-01,  5.5425e-01,  1.9574e-01, -9.6649e-02, -2.1523e-01,\n",
       "         -4.0535e-01, -5.7623e-01, -1.7160e-01,  2.7072e-01, -5.2322e-01,\n",
       "         -8.2474e-01, -1.3010e+00, -2.1880e-02,  9.1504e-01, -5.0393e-01,\n",
       "          1.8200e-01, -5.7139e-01, -6.8260e-01,  2.6521e-01,  7.5730e-01,\n",
       "         -6.5971e-01, -2.4942e-01, -6.3877e-01,  3.7042e-02, -1.1593e+00,\n",
       "          2.6999e-01,  2.6256e-01, -4.4169e-01, -9.9663e-01, -1.3813e+00,\n",
       "         -5.6294e-01,  3.6400e-01, -6.9520e-01,  7.4651e-01, -1.1409e-01,\n",
       "          1.7199e-01,  1.2988e+00,  1.0902e-02, -3.6763e-01, -1.9660e+00,\n",
       "          9.2131e-01, -1.6520e+00,  4.0538e-01,  1.1315e-01, -6.2344e-01,\n",
       "         -5.4987e-01,  1.7111e-02,  6.6484e-01, -3.0472e-01, -8.8806e-01,\n",
       "         -1.4218e+00, -2.5646e+00,  1.3686e+00, -2.8031e-01, -1.0274e+00,\n",
       "         -3.6000e-01, -1.6051e+00, -1.4549e+00, -2.1120e+00, -1.0716e+00,\n",
       "         -7.8746e-01, -1.9793e-01, -9.9617e-01,  1.2867e+00,  1.1996e+00]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# forward pass\n",
    "prediction = model(data)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "25bc409a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-505.1766, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = (prediction - labels).sum()\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e21a0dd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0a98653f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9e268712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGD (\n",
       "Parameter Group 0\n",
       "    dampening: 0\n",
       "    differentiable: False\n",
       "    foreach: None\n",
       "    fused: None\n",
       "    lr: 0.01\n",
       "    maximize: False\n",
       "    momentum: 0.95\n",
       "    nesterov: False\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optim = torch.optim.SGD(\n",
    "    model.parameters(),\n",
    "    lr=1e-2,\n",
    "    momentum=0.95\n",
    ")\n",
    "optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6f25aba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77cb2c6",
   "metadata": {},
   "source": [
    "# differentiation in autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fd62f76a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([3., 4.], requires_grad=True), tensor([5., 7.], requires_grad=True))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.tensor([3., 4.], requires_grad=True)\n",
    "b = torch.tensor([5., 7.], requires_grad=True)\n",
    "a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "06dd54d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 56., 143.], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q = 3*a**3 - b**2\n",
    "Q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1312dc",
   "metadata": {},
   "source": [
    "if we have `a` and `b` be the parameters of the NN, and `Q` to be the error, then we want the gradients of the errors to be the partial derivatives with respect to the parameters. Calling something like `.backward()` on `Q`, the autograd function will automatically calculate the partial derivatives (graidents and store them in the tensor's `.grad` attribute). a specific `gradient` argument is neeeded in `Q.backward()` since it is a vector. We can also aggregate `Q` into a scalar using `.sum()`, then pass the backward argument on top. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c2fa9a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "external_grad = torch.tensor([1., 1.])\n",
    "Q.backward(gradient = external_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1ba8abe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([3., 4.], requires_grad=True),\n",
       " tensor([5., 7.], requires_grad=True),\n",
       " tensor([ 56., 143.], grad_fn=<SubBackward0>))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, b, Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8be09a2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 81., 144.]), tensor([-10., -14.]))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.grad, b.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f9f07f58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 81., 144.], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "9*a**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6e4d4722",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-10., -14.], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-2*b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2628a759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([True, True])\n",
      "tensor([True, True])\n"
     ]
    }
   ],
   "source": [
    "print(9*a**2 == a.grad)\n",
    "print(-2*b == b.grad)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

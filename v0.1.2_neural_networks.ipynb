{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01a4878c",
   "metadata": {},
   "source": [
    "# Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6b3bac",
   "metadata": {},
   "source": [
    "neural netowrks can be constructed using the `torch.nn` package. the `nn.Module` contains layers and a method called `forward(input)` that passes it forward and returns the output. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff760239",
   "metadata": {},
   "source": [
    "A simple neural network is trained as follows: \n",
    "\n",
    "- define the neural network with the learnable parameters/weights\n",
    "- iterate over the dataset of inputs\n",
    "- forward pass through the network\n",
    "- compute the loss (how far it is from being correct with the loss, even loss function)\n",
    "- propagate the gradients back into the network's parameters\n",
    "- update the weights of the network, usikng a simple rule like `w = w - lr * grad`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183030d4",
   "metadata": {},
   "source": [
    "# Define a simple network using this cnn style of networks:\n",
    "\n",
    "![mnist classification cnn](figures/mnist.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb1fc7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d96026ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    '''\n",
    "    Note that this net is not exactly the same as the above image\n",
    "    '''\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(Net, self).__init__(*args, **kwargs)\n",
    "        # first, take 1 input channel, 6 output channel, 5x5 square convolution\n",
    "        # note that these convolution blocks are image size agnostic. we just have to keep the image size in mind when we're desigining this netowkr\n",
    "        # for example, the mnist images are 32x32 in size. \n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
    "        # then use linear operations\n",
    "        self.fc1 = nn.Linear(in_features=16*5*5, out_features=128) # note that the 5*5 is from the image dimension but I'm not sure about this yet\n",
    "        self.fc2 = nn.Linear(in_features=128, out_features=64)\n",
    "        self.fc3 = nn.Linear(in_features=64, out_features=10)\n",
    "\n",
    "    def forward(self, input):\n",
    "        # the first convolution layer C1, in inpout image, 6 output channnels\n",
    "        # outputs tensor with size (N, 6, 28, 28), N is batch size, reduces image 32 - 5 (kernel size) +1= 28\n",
    "        c1 = F.relu(input=self.conv1(input))\n",
    "        # subsample this layer with pooling\n",
    "        # this pools the information from the 28x28 layer with a square that is 2x2 and outputs the max of those values, which is 14x14\n",
    "        s2 = F.max_pool2d(input=c1, kernel_size=(2, 2))\n",
    "        # convolution layer agian, l3, 6 channels in and 16 out\n",
    "        # out dimensions is 14 - 5 + 1 = 10\n",
    "        c3 = F.relu(input=self.conv2(s2))\n",
    "        # another pooling layer, reduces the 14x14 layer to a 7x7 layer\n",
    "        s4 = F.max_pool2d(input=c3, kernel_size=(2, 2))\n",
    "        # flatten this output to prep for the linear layers:not sure which flatten dimension to use\n",
    "        s4 = torch.flatten(input=s4) # out goes a 16*5*5 = 400 dimensional nerual network\n",
    "        # now for the activation functions for the linear layers, this is fairly straightforward\n",
    "        f5 = F.relu(input=self.fc1(s4)) # out goes a N, 128 dimensional output\n",
    "        f6 = F.relu(input=self.fc2(f5)) # out N, 64\n",
    "        output = self.fc3(f6)\n",
    "        return output\n",
    "    \n",
    "net = Net()\n",
    "print(net)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20757c2",
   "metadata": {},
   "source": [
    "note that while the `forward` function was just defined, the `backward` function where the gradients are computed is automatically defined with `autograd` whoooo. use any Tensor operation you want in the `forward` function\n",
    "\n",
    "you can also get the number of learnable parameters in `net.parameters()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f91ccad9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x78d0b423bae0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.parameters() #should return a generator object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfeef7d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = list(net.parameters())\n",
    "len(params) # 10 layers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c085e68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1044, -0.1355,  0.1908,  0.0707, -0.1965],\n",
       "         [ 0.0639,  0.1531, -0.0630,  0.0156, -0.1934],\n",
       "         [ 0.0881, -0.0381, -0.0146, -0.0249,  0.0553],\n",
       "         [-0.0273,  0.1094, -0.1052,  0.1564,  0.0914],\n",
       "         [ 0.0116, -0.0097, -0.1954, -0.0093,  0.1783]]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for instance, this is the randomly selected 5x5 convolution window for the first layer.\n",
    "params[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1faadf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0128, -0.0482, -0.0798,  0.0624, -0.0147],\n",
       "        [-0.0268, -0.0454,  0.0803, -0.0301,  0.0623],\n",
       "        [ 0.0436, -0.0441, -0.0191, -0.0524,  0.0160],\n",
       "        [ 0.0390,  0.0655, -0.0467, -0.0086,  0.0659],\n",
       "        [-0.0019, -0.0101,  0.0623,  0.0391, -0.0108]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is the one for the 3rd layer, 5th block along the length, and 2nd 5x5 conv block\n",
    "\n",
    "params[2][4][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5310ae55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 0\n",
      "torch.Size([1, 5, 5])\n",
      "layer 1\n",
      "torch.Size([])\n",
      "layer 2\n",
      "torch.Size([6, 5, 5])\n",
      "layer 3\n",
      "torch.Size([])\n",
      "layer 4\n",
      "torch.Size([400])\n",
      "layer 5\n",
      "torch.Size([])\n",
      "layer 6\n",
      "torch.Size([128])\n",
      "layer 7\n",
      "torch.Size([])\n",
      "layer 8\n",
      "torch.Size([64])\n",
      "layer 9\n",
      "torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "for layer, parameter in enumerate(params):\n",
    "    print(f\"layer {layer}\")\n",
    "    print(parameter[0].size()) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa43bb0d",
   "metadata": {},
   "source": [
    "note that there are a few that do not have any paramters. these are, you guessed it, the functional parts. they are functions, and don't have paramters (usually)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7f82e2f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 6.7301e-01, -5.7621e-01,  2.4888e-01,  ...,  6.2546e-01,\n",
       "           -3.9181e-01,  2.2146e+00],\n",
       "          [ 4.2308e-01, -4.5661e-01, -2.7623e-01,  ..., -1.8511e+00,\n",
       "           -1.0529e+00,  5.5897e-01],\n",
       "          [ 7.5715e-01, -1.2491e-04, -4.6608e-01,  ...,  5.8265e-01,\n",
       "            5.6940e-01, -1.3647e+00],\n",
       "          ...,\n",
       "          [-9.1382e-01, -2.9432e-01,  1.6746e+00,  ...,  9.0933e-01,\n",
       "            1.5600e+00, -1.2230e+00],\n",
       "          [-6.1336e-01, -2.0824e-01, -9.8287e-01,  ..., -1.7465e-01,\n",
       "           -7.1466e-01,  3.6712e-01],\n",
       "          [-2.8719e-01,  3.0115e-02,  6.9557e-01,  ..., -3.2516e-01,\n",
       "           -2.6736e-01, -2.4108e+00]]]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random input\n",
    "\n",
    "input = torch.randn(size=(1, 1, 32, 32))\n",
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e7f41e5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0319,  0.0830,  0.1436, -0.1129,  0.0279,  0.0280,  0.1433, -0.0944,\n",
       "        -0.0667,  0.0990], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = net(input)\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363812eb",
   "metadata": {},
   "source": [
    "what pytorch will do is accumulate the gradients for all the backward passes. this means that for each batch, the new gradients will be added ot the existing ones, and you have to set them to zero if you want to do so before each new training iteration/batch. training will break if the gradients are not cleared. for each batch, you want to update the gradient accordingly. sometimes, you want to accumulate the gradients, say, to save memory and simulate a larger batch size for a smaller GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "45d6ec3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b70a26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0319,  0.0830,  0.1436, -0.1129,  0.0279,  0.0280,  0.1433, -0.0944,\n",
       "        -0.0667,  0.0990], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.backward(torch.flatten(torch.randn(1, 10))) # with a random label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ffc1c3",
   "metadata": {},
   "source": [
    "> Note that `torch.nn` ony suppoprts batches and **not single samples**. this means that the if you have a single sample, simply use `input.unsqueeze(0)`\n",
    "\n",
    "now just to recap\n",
    "\n",
    "- `torch.Tensor`: a multidimensional array with support for `autograd` and it's operations, holds gradients with respect to the tensor itself\n",
    "- `nn.Module`, neural netowrk module, convenient way of encapsulating the parameters\n",
    "    - includes helpers to move them to the GPU, io, etc\n",
    "- `nn.Parameter` sort of a tensor that automatically registered as a parameter when assigned an attribute to a MOdule\n",
    "- `autograd.Function` implements the forward/backward passes of a module. every `Tensor` creates at least a single `Function` note that connects to functions that created a tensor and encodes its history."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302a3ece",
   "metadata": {},
   "source": [
    "# Loss functions\n",
    "\n",
    "a loss function compues a value that is supposed to illustrate the difference (loss) of the io values. a simple loss is Mean Square Error loss, which is `nn.MSELoss`, computing the mse "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "865db08d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.9250, -2.5162, -0.0027, -1.1703,  1.9402, -0.0717,  0.4340,  0.2116,\n",
       "         0.2472, -1.8958])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2e6892",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.0319,  0.0830,  0.1436, -0.1129,  0.0279,  0.0280,  0.1433, -0.0944,\n",
       "         -0.0667,  0.0990], grad_fn=<ViewBackward0>),\n",
       " tensor([-0.1414,  0.4394,  2.1626, -0.3430, -1.3231,  0.6644,  1.6357, -0.8177,\n",
       "          0.1454, -0.3506]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = net(input)\n",
    "target = torch.randn(10)\n",
    "output, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34827c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9514, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# defining the criterion\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "loss = criterion(output, target) # must be in the order of (prediction, target)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92ad8ad",
   "metadata": {},
   "source": [
    "if you want to follow the gradients backwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6e1d7646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MseLossBackward0 object at 0x78d094c04c40>\n",
      "<ViewBackward0 object at 0x78d094c04c40>\n",
      "<AddmmBackward0 object at 0x78d095f08c10>\n"
     ]
    }
   ],
   "source": [
    "print(loss.grad_fn)  # MSELoss\n",
    "print(loss.grad_fn.next_functions[0][0])  # Linear\n",
    "print(loss.grad_fn.next_functions[0][0].next_functions[0][0])  # ReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a642f8c",
   "metadata": {},
   "source": [
    "# backpropagation\n",
    "\n",
    "backpropagation, especially for linear layers are very straightforward. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "333825fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.bias.grad before the backprop\n"
     ]
    }
   ],
   "source": [
    "net.zero_grad()     # this is the gradient zeroed out/buffer cleared for all parameters\n",
    "\n",
    "print(\"conv1.bias.grad before the backprop\")\n",
    "net.conv1.bias.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e4b5e4b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.bias.grad before the backprop\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.0082, -0.0165, -0.0036, -0.0217, -0.0060, -0.0108])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.backward()     # after the backprop\n",
    "\n",
    "print(\"conv1.bias.grad before the backprop\")\n",
    "net.conv1.bias.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd1c53d",
   "metadata": {},
   "source": [
    "# update the weights of the network\n",
    "\n",
    "now we just have to update the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5fee45dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a simple way to do this using code:\n",
    "lr = 0.01\n",
    "for p in net.parameters():\n",
    "    p.data.sub_(p.grad.data * lr) # with the _ decorator at the end, it just is an inplace operation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf843cfb",
   "metadata": {},
   "source": [
    "in order to fully utililze the power of pytorch, you should really just use an abstracted optimizer for this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "eb0c8d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.SGD(net.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fce78a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# then in the trainig loop:\n",
    "\n",
    "optimizer.zero_grad() # zero gradients\n",
    "output = net(input)\n",
    "loss = criterion(output, target)\n",
    "loss.backward()\n",
    "optimizer.step() # does the update itself"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9a75466",
   "metadata": {},
   "source": [
    "# huggingface demo repo with bert base chinese \n",
    "\n",
    "primary demo for `AutoModelForSequenceClassification`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8375db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 14:54:46.473405: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-30 14:54:46.518206: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import joblib\n",
    "from datasets import Dataset, concatenate_datasets, load_dataset\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForSequenceClassification,\n",
    "    TrainingArguments, Trainer, DataCollatorWithPadding,\n",
    "    pipeline, AutoModel \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66f04a5",
   "metadata": {},
   "source": [
    "defining model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "168cf046",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = 'google-bert/bert-base-chinese'\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ee6ff26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-chinese and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=14, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            MODEL, \n",
    "            num_labels=14,\n",
    "            trust_remote_code=True, \n",
    "            ).to(DEVICE)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4921975",
   "metadata": {},
   "source": [
    "tokenizer & data collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18ae8b44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertTokenizerFast(name_or_path='google-bert/bert-base-chinese', vocab_size=21128, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "983f1e4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataCollatorWithPadding(tokenizer=BertTokenizerFast(name_or_path='google-bert/bert-base-chinese', vocab_size=21128, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}\n",
       "), padding=True, max_length=None, pad_to_multiple_of=None, return_tensors='pt')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_collator = DataCollatorWithPadding(\n",
    "    tokenizer=tokenizer\n",
    "    )\n",
    "data_collator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdece700",
   "metadata": {},
   "source": [
    "data loading, tokenizing, sorting labels, encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fe13cb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'text', '__index_level_0__'],\n",
       "        num_rows: 4917\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', 'text', '__index_level_0__'],\n",
       "        num_rows: 258\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Methods and `google-bert/bert-base-chinese`\n",
    "dataset = load_dataset(\n",
    "    'parquet', \n",
    "    data_files={\n",
    "        'train': 'data/train_zh.parquet',\n",
    "        'test': 'data/test_zh.parquet'\n",
    "    })\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f4188c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = dataset.sort(column_names='label')\n",
    "# dataset['train']['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "564652ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoded_dataset = dataset.class_encode_column('label')\n",
    "# encoded_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1158674",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_dataset(dataset):\n",
    "    return tokenizer(\n",
    "        dataset[\"text\"],\n",
    "        max_length=tokenizer.model_max_length, \n",
    "        truncation=True,\n",
    "        padding='max_length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e04155a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cc1e0752b3c4b1f870ee93c0c1ee9f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/258 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tok_dataset = encoded_dataset.map(tokenize_dataset, batched=True)\n",
    "tok_dataset = dataset.map(tokenize_dataset, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77753a8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'text', '__index_level_0__', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 4917\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', 'text', '__index_level_0__', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 258\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01621ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique labels: 14\n",
      "Label values: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n"
     ]
    }
   ],
   "source": [
    "# Before creating the model, check your labels\n",
    "unique_labels = set(dataset['train']['label'])\n",
    "num_labels = len(unique_labels)\n",
    "print(f\"Number of unique labels: {num_labels}\")\n",
    "print(f\"Label values: {sorted(unique_labels)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8ed07a",
   "metadata": {},
   "source": [
    "defining data collator, training args, and trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3a7cd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='train/demo',\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "510c9684",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tok_dataset['train'],\n",
    "    eval_dataset=tok_dataset['test'],\n",
    "    data_collator=data_collator,\n",
    "    processing_class=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0829e540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1230' max='1230' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1230/1230 04:01, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.581600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.307900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1230, training_loss=0.40971578272377573, metrics={'train_runtime': 241.9031, 'train_samples_per_second': 40.653, 'train_steps_per_second': 5.085, 'total_flos': 2587712896733184.0, 'train_loss': 0.40971578272377573, 'epoch': 2.0})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6386a997",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final metrics: {'eval_loss': 0.22594906389713287, 'eval_runtime': 1.9793, 'eval_samples_per_second': 130.352, 'eval_steps_per_second': 16.673, 'epoch': 2.0}\n"
     ]
    }
   ],
   "source": [
    "eval_results = trainer.evaluate()\n",
    "print(\"Final metrics:\", eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed3ae4f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6093169dd3b4494fae096f326cb33dba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0)                : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1253c7cc0cff45b78cdcf5a40c1d0d15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload                         : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1aedea51d43542199dfcf1baeed288f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...l-demo/train/demo/model.safetensors:   6%|5         | 23.0MB /  409MB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55f70bc41f2b464c8f5b347dc610d3f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...nts.1759178625.workstation.191437.0:   1%|          |  47.0B / 5.11kB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a2b8c8c529a456a914add4292e4aad5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...nts.1759178796.workstation.191437.1:   1%|          |  47.0B / 5.11kB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e49fc3dfd9a54370b502eae1df3817be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...nts.1759178989.workstation.191437.2:   1%|          |  47.0B / 5.11kB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08b549710987433c8838066aef079883",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...nts.1759179027.workstation.191437.3:   1%|          |  47.0B / 5.11kB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "434184e397464880894c317cda8c2a73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...nts.1759179109.workstation.191437.4:   1%|          |  47.0B / 5.11kB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "913df90504f942be9d671b66a8c82f23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...nts.1759179182.workstation.191437.5:   1%|          |  47.0B / 5.11kB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff28ed31afb04b4389764a4689130328",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...nts.1759180861.workstation.191437.6:   1%|          |  93.0B / 10.1kB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64d9f4eb7f2045378e36665cb3e0bfd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...nts.1759181037.workstation.191437.7:   1%|          |  47.0B / 5.11kB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75bba8373e0c434f8dc8f21769f5f64c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...nts.1759181262.workstation.254654.0:   1%|          |  47.0B / 5.11kB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/mxngjxa/demo/commit/74f369cbec6abe875284fa9cefc1754768945079', commit_message='mxngjxa/demo-model', commit_description='', oid='74f369cbec6abe875284fa9cefc1754768945079', pr_url=None, repo_url=RepoUrl('https://huggingface.co/mxngjxa/demo', endpoint='https://huggingface.co', repo_type='model', repo_id='mxngjxa/demo'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.push_to_hub('mxngjxa/demo-model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
